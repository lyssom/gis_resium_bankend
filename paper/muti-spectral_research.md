## 1　引 言

遥感对地观测是环境保护、资源调查、军事侦察等国家重大需求的核心关键技术，被布局到《国家中长期科技发展规划纲要（2006—2020年）》等多个国家计划（童旭东，2018）。随着多光谱、高光谱、红外、合成孔径雷达、夜光等遥感对地观测技术的发展，遥感成像手段呈现多样化的趋势（孙伟伟 等，2020）。同一场景的多源遥感图像拍摄的地物对象相同，但图像分辨率、视场和图像反映的目标特性存在差异，提供的多源信息既具有冗余性，又具有互补性和合作性。多源遥感图像融合能够综合利用不同传感器获取的图像信息，实现更精准、更全面的遥感对地观测，已成为遥感领域的研究热点（Mahyari和Yazdi，2011；Yokoya等，2012；Zhu和Bamler，2013；Li等，2013；Tuia等，2017）。如图1所示，本文检索了Web of Science（WOS）和中国知网（CNKI）遥感图像融合相关论文的发表情况，检索条件为文献关键词包含“遥感”与“融合”，从近十年文献数量的变化趋势可以看出，论文数量呈逐年上升的趋势，多源遥感图像融合已成遥感领域的热点问题。

地理测绘是获取、处理和表达地理空间信息的重要手段，广泛应用于国土资源管理、环境监测、城市规划等诸多领域。传统的测绘方式存在数据获取困难、处理效率低下、成果表达单一等问题。地理信息系统（GIS）作为一种先进的空间信息技术，能够高效管理和分析地理数据，为解决测绘中的难题提供了新思路。GIS 将地理编码数据与图形显示相结合，支持空间查询、叠加分析等高级功能，使得海量异构空间数据的集成和综合分析成为可能。论文将从数据采集、处理和成果表达三个环节，系统分析 GIS 在地理测绘中的应用效果。

国内外学者已发表多篇综述，从不同角度介绍了现有的多源遥感图像融合方法。例如，武汉大学张良培和沈焕锋（2016）将遥感图像融合分为同质遥感数据融合、异质遥感数据融合、遥感—站点数据融合和遥感—非观测数据融合，并着重对时空谱融合的研究现状作了详细阐述。中国科学院遥地所张立福等（2019）通过对遥感图像融合领域的论文发表情况进行统计和梳理，将遥感图像融合概括为面向空间维提升的融合方法、面向光谱维提升的融合方法和面向时间维提升的融合方法。德国宇航局Schmit和Zhu（2016）将遥感图像融合归纳为像素级、特征级与决策级3类典型的融合框架，并通过遥感领域国际期刊上图像融合相关论文的发表数量、国际遥感数据融合竞赛结果分析了多源遥感图像融合的研究现状。Ghamisi等（2019）重点介绍了多分辨率图像融合、多时相图像融合、光学与激光雷达图像融合，以及遥感图像与社交媒体信息、地学信息等融合的研究现状。随着人工智能技术的兴起，深度学习在遥感图像融合领域引发了新一轮的研究热潮。Liu等（2018b）介绍了主流的深度学习图像融合方法，并将这些方法归纳为几类通用的深度学习图像融合框架。

除上述综述性文章外，部分学者旨在通过多类融合方法的实验比较与分析，或是通过数学模型的对比分析阐明不同多源融合方法的优缺点和适用性。Garzelli等（2004）与Alparone等（2007）对当时性能最优的多光谱和全色图像融合方法的融合性能进行了对比研究。Loncan等（2015）将传统全色与多光谱融合方法扩展应用于多光谱与高光谱图像融合，并在多个真实遥感数据集上通过评估不同方法的有效性和鲁棒性。Yokoya等（2017）在多个真实遥感数据集上对比了十种典型的图像融合方法，并详细介绍了不同方法的适用性。肖亮等（2020）从贝叶斯融合建模的角度分析了现有空谱融合方法的建模机理，阐明了遥感图像融合模型的发展趋势，指出了遥感图像空谱融合领域亟待突破的技术瓶颈。

与上述遥感图像融合综述不同。本文从多源遥感数据的源头出发，首先介绍了全色、多光谱、高光谱、红外、合成孔径雷达、激光雷达等9类典型多源遥感图像的获取方式、图像特性与典型应用；然后，阐明了不同类型多源遥感图像融合方法的研究现状与面临的挑战性难题；最后，对多源遥感图像融合的整体发展趋势与未来可能的研究方向进行了展望。

## 2　多源数据融合效果

## 2.1  多源遥感图像

遥感是利用卫星、飞机等平台上的成像仪，采集地球表面或近地空间的电磁波，探测和识别地球资源和环境信息的技术（Gu和Tong，2015；Guo，2012；Guo等，2019）。如图2所示，不同来源获取的遥感图像其成像原理不同，图像的空间分辨率、观测尺度以及反映的目标特性也会存在差异。

全色、多光谱和高光谱图像均通过光学成像手段获取。光学成像时，光电感应装置将光信号转换为电信号，量化后的电脉冲信号记录为像素值。成像的过程是对电磁波能量的采样，在光谱维采样得到光谱信息，在空间维采样得到空间信息，受限于传感器的采样极限，成像系统不得不在空间和光谱信息上有所权衡。全色图像只有一个波段，波段范围在0.50—0.75
 μm之间，图像显示为灰度图片，其空间分辨率高，包含地物细节信息丰富，能够获取地物精细的几何和纹理特征，但缺乏光谱信息（唐华俊 等，2010）。

多光谱图像具有多个波段的光谱信息，其空间和光谱分辨率介于全色图像与高光谱图像之间，因此多光谱图像在融合过程中可为全色图像提供光谱信息，也可为高光谱图像提供空间信息。多光谱图像的光谱波段通常是经过严格设计的，按一定的顺序进行波段组合和数学运算，便可在图像上突出植被、水体、海岸线等特定的目标地物，例如，黄安等（2015）利用Landsat 8 OLI多光谱图像特定波段组合检测大尺度场景下的城市区域；罗代清等（2016）使用Landsat 5 TM多光谱图像的第3、4、5波段的组合，对湖北省麻城市杜鹃花的分布范围进行监测；李晓民等（2016）使用资源一号02C卫星多光谱图像的前3个波段进行组合，对西藏扎达地区的水文地质进行评估调查。

高光谱图像具有几十甚至上千个光谱波段，能够捕捉地物精细的光谱信息，光谱范围大，波段信息丰富，常用于地物的精细分类与识别，在城乡规划、精准农业、环境监测等领域有广泛的应用需求。例如，韦安娜等（2020）通过高分五号卫星获取的高光谱图像对鄱阳湖叶绿素浓度进行反演，以衡量该地区水体的富营养化程度。但更高的光谱分辨率意味着更低的空间分辨率，在图像质量和空间分辨率上会有所受限（王建宇 等，2010）。因此，在实际应用中，常常将高光谱图像与多光谱、全色和合成孔径雷达图像进行融合处理，以得到更高空间分辨率的高光谱图像。如Adiri等（2020）将EO-1卫星获取的高光谱图像与Landsat 8，Sentinel-2A卫星获取的多光谱图像进行融合，并成功应用于摩洛哥铜矿区的精细制图；Ren等（2020）以鄱阳湖、太湖和黄河口为研究区域，在高分五号（高光谱）、高分一号（全色）、高分二号（多光谱）、Sentinel-2（多光谱）数据上对比了9种图像融合方法的优劣。

热红外遥感图像反映了地物的温度分布。红外线IR

（Infrared）在电磁波频谱中处于可见光与无线电波之间，自然界中一切温度高于绝对零度的物体会向外辐射红外线。成像系统接收到目标的红外辐射，在处理后转换成红外热成像图。红外遥感成像一般应用于地表温度反演与热环境分析，已成功应用消防、地质等领域（姜荣，2016；谢苗苗 等，2008；Raynolds等，2008）。例如，吴文渊等（2019）利用Landsat 8 OLI/TIRS获取的红外遥感图像反演地表温度，分析浙江省冬季地表热环境及其影响因子；独文惠等（2018）综述了热红外遥感在农业旱情监测中的应用进展，指出热红外遥感为实现实时动态农业旱情检测开辟了新途径，具有不可替代的作用。

夜间灯光NTL （Night Time Light）遥感图像可以捕获夜间地表微弱的灯光辐射，且具有大尺度对地观测的优势（李德仁和李熙，2015；陈颖彪 等，2019）。目前常用的夜光数据，国外有国防气象卫星计划
 DMSP （Defense Meteorological Satellite 
Program）卫星上搭载的线性扫描业务系统（OLS）所获取的夜光数据，还有新一代的夜间灯光数据NPP/VIIRS（National 
Polar-Orbiting Partnership’s Visible Infrared Imaging Radiometer 
Suite）等（唐鹏飞 等，2020）。国内珞珈一号和吉林一号卫星是中国夜光遥感图像的重要来源。夜光遥感给人类活动的观测提供了重要的契机，在估算社会经济参数，城市化评估、监测灾难和地域冲突、渔业研究等方面发挥着不可或缺的作用（Levin等，2020）。例如，张国亮等（2020）利用吉林一号夜光遥感图像，开展了城市发展情况及人类活动监测、住房空置率监测和耗电量监测研究；张宝军（2018）基于DMSP/OLS夜光数据，分析了2003年—2013年汶川地震极重灾区夜间灯光分布的范围和强度的变化，并与地区和社会经济因素相联系，探索灾区夜间灯光变化与灾害损失之间的相关关系。

立体遥感图像通常是靠空间体视效应实现三维深度信息的获取。人的双眼就是一种典型的体视仪器，遥感立体成像借鉴了人类的双目视觉感知功能，通过多个角度的遥感图像获取场景的三维深度信息（胡家升 等，1997）。目前常用的空间立体成像方案主要是在卫星载体上安装多台不同观测角度的光学相机，或者通过卫星在敏捷平台上变换姿态，获得地物目标在不同角度的图像，用于估计场景的三维信息。立体遥感图像一般用于生产和更新基础地理产品、进行国土资源调查与监测，因此，立体成像测绘卫星已发展为重要的战略资源，各国都将测绘卫星的发展作为其卫星与应用发展规划中的重中之重（郭连惠和喻夏琼，2013）。中国第一颗民用立体测图卫星是资源三号测绘卫星，它的成功发射对中国测绘事业的发展具有革命性意义，实现了全国范围高分辨率立体图像长期稳定的获取（李德仁，2012；郭莉 等，2017）。中国2019-11成功发射的高分七号卫星，搭载的双线阵立体相机达到了0.8 m的空间分辨率，能更好的满足实际应用的需求（刘建军 等，2018；Tang等，2020）。

视频遥感数据是近年来在遥感领域出现的新型对地观测数据。随着欧比特视频卫星1A、1B的成功发射，中国视频卫星遥感技术发展迅速。与传统的卫星数据相比，视频遥感数据最大的优势是可以对同一区域进行“凝视”观测，视频相比于图像可以展现目标或场景的动态变化信息，尤其适用于对目标进行连续观测和跟踪。因此，视频遥感数据在地质灾害监测、违规采矿监测、战场动态监控等应用中具有重大应用前景（詹桓，2017）。

合成孔径雷达SAR
 （Synthetic Aperture 
Radar）利用了多普勒频移理论和雷达相干原理，是一种主动成像方式。合成孔径雷达一般由天线阵列构成，各天线阵元之间相互干涉形成较窄波束，当星载或机载雷达沿着轨道飞行时，合成孔径雷达发出微波，由于地面目标与雷达间存在着相对运动，雷达将接收到的回波信号进行迭加，回波信号转换成电信号并记录成数字化像元，形成SAR图像（刘国祥，2004）。合成孔径雷达记录的回波信号是地物的后向散射能量，能够反映地物的表面特性和介电性质。此外，得力于合成孔径成像机制，SAR在方位和距离上都能获得很高的几何分辨力，突破了经典雷达的分辨极限。使用主动微波成像，穿透作用较强，能够有效探测伪装目标，且成像不受光线、气候和云雾限制，故在军事侦察、地理测绘、灾害监测等领域具有很高的实际应用价值（崔麦会 等，2004）。此外，部分地物具有独特的微波反射特性，如金属、树林等地物的微波反射率远远高于其他地物，麦穗、砾石等大小与雷达波长相等的物体会与雷达波产生谐振，形成强烈回波。因此，SAR图像可以反映远小于图像分辨率的某些地物，如高压线、铁路等（何国金和李克鲁，1997）。基于合成孔径雷达的工作特性，利用相位差获取地形高程数据的合成孔径雷达干涉测量技术（InSAR）已经得到工程化应用，并成为地表形变监测的重要手段。此外，电磁波的另一属性—极化，是除频率、相位和幅度之外的重要属性，极化SAR系统

（PolSAR）已经成为一种比较成熟的技术，即接收和发送的电磁波以水平（H）和垂直（V）方向任意组合，常用极化方式有单极化、双极化和全极化。极化SAR图像的优势在于丰富了目标的散射信息，增加了目标观测和感知的维度，在农业、地质、水文和海冰监测方面都得到了广泛研究和应用。例如，郭兆明等（2019）使用美国Lacrosse-5 SAR数据对运动车辆进行监测；Chaturvedi 等（2020）利用Sentinel-1极化SAR图像对沙特和科威特交界处拉斯海夫吉地区溢油区域进行监测。

激光雷达LiDAR
 （Light Detection And 
Ranging）也是一种主动成像方式，其成像原理与合成孔径雷达类似，是工作在红外至紫外区间的光频波段雷达。激光雷达具有很好的单色性、方向性与相干性，激光能量集中，探测灵敏度和分辨率高，可以精确跟踪识别目标的运动状态和位置。与合成孔径雷达相比，激光雷达的激光束窄，故其被截获的概率很低，隐蔽性好。功能相似的情况下，激光雷达装置的体积比均合成孔径雷达要小
 （蔡悦，2020），被成功应用于城市三维建图、气象监测、油气勘察、环境保护等领域。例如，Ma等（2020） 基于红外探路者卫星（CALIPSO）获取的激光雷达数据分析了十年来北京、纽约、伦敦和新德里白天和夜间的大气颗粒物浓度；Jarron等（2020）利用机载激光雷达数据估算加拿大不列颠哥伦比亚省中部森林地亚冠层森林结构，为选择性伐木、火灾预防和野生动物栖息地保护提供技术支撑；余柏蒗等（2010）将机载LiDAR数据与高分辨率遥感图像结合，对美国休斯顿中心城区进行地物分类与制图。

表1概括了目前遥感领域9种不同来源的遥感图像及其对应的卫星与机载成像平台（孙伟伟 等，2020；Zhang等，2014；Chaussard等，2014；Liu等，2018a；Park等，2003；Thenkabail等，2004）。如表1所示，遥感图像的获取方式呈现多样化的趋势，但发展并不十分均衡。多光谱与全色成像是最成熟的遥感成像手段。激光、立体、红外图像获取手段相对较少。值得注意的是合成孔径雷达卫星由于具有全天时、全天候的优势，在军事中应用十分广泛。本综述中统计的机载和星载合成孔径成像平台难以全面反映雷达成像技术的发展现状。

（1）多源数据的丰富性和可靠性促进了遥感图像融合技术的发展。全色与多光谱图像融合技术发展迅速，很大程度上得益于星载全色多光谱成像平台的发展。例如，国内高分一号、高分二号，国外WorldView系列卫星等均同时搭载了全色相机与多光谱相机，为全色与多光谱图像融合提供了丰富的数据源。

（2）不同来源遥感图像融合的发展并不十分均衡，一方面是由于不同来源图像的互补性较弱所导致。例如，合成孔径雷达与激光雷达互补性较弱，因此相关的研究也较少。另一方面是由于部分新兴的图像获取手段尚未引起学者们足够的关注。例如，夜间灯光图像、视频图像、立体图像和其他不同来源图像的融合。

因此，多源遥感图像融合未来的发展方向主要体现在两个方面。

一方面，现有研究主要集中在全色、多光谱、高光谱、SAR以及LiDAR图像的融合。夜光、视频、立体相机等新型成像手段的出现，为多模遥感图像融合技术的发展提供了新数据。因此，如何将夜光、视频、立体相机等数据和其他类型的遥感图像数据进行融合是未来新的发展方向。

另一方面，如何将图像融合与成像系统的设计相结合，构建多种探测手段合一的融合成像系统，是未来重要的研究方向之一。例如，长春理工大学姜会林等人联合国家海洋局、湖南大学、西安交通大学等多家单位联合承担了一项国家自然科学重大基金“海洋监测多维高分辨光学成像理论与方法”。该项目的核心是将遥感图像融合技术与光学成像系统的设计、海洋环境下光传输与反射的机理结合起来，建立一套集光谱、红外、偏振于一体的机载多维高分成像系统。北京信息科技大学邱均等人承担了一项国家自然科学基金重点基金“面向滨海湿地鸟类监测的多维协同全光计算成像技术”。这类研究旨在建立多维度的协同观测系统，图像融合技术在其中发挥了至关重要的作用。换言之，仅依靠现有的卫星遥感和机载数据开展图像融合研究存在诸多局限。将图像融合技术与成像系统设计、遥感应用问题相结合是多源遥感图像融合未来的发展趋势。

## 2.2  GIS 在地理测绘数据采集中的效果

地理测绘工作对数据的精度要求极为严格，任何微小的误差都可能导致重大决策失误。传统的人工测量和记录方式存在一定的主观性和不确定性，难以满足现代测绘的高精度需求。GIS 技术则能够显著提高数据采集精度。它利用全球导航卫星系统（GNSS）、航空遥感、地理雷达等先进手段，直接获取高分辨率的地理坐标和属性数据，有效克服了人为测量的局限性。以 GNSS 技术为例，其测量精度可达分米甚至厘米级，大大高于传统的全站仪测量。GIS 还可采用差分数据处理等方法，进一步消除坐标偏差，确保数据的准确性

## 2.3 多源异构数据采集

GIS 能够集成处理多种异构数据，从而支持通过不同方式和工具对地理实体进行全面、多角度的采集。这为打破传统单一数据获取手段的局限性，实现数据采集的多元化奠定了基础。例如，GIS 不仅可采集 GNSS、全站仪等传统测量数据，还可导入规范化的遥感影像、激光雷达点云等新型数据。此外，通过移动终端、物联网等新型采集载体，更加贴近实际需求主动采集数据，适应了多元地理环境的应用需求。多源异构数据的融合不仅丰富了数据内容，还有助于数据采集质量的提升。在 GIS 环境下，主辅数据相互校正、交叉验证，可以最大程度消除各自存在的误差，提高总体精度。如将地面 GPS 测量与遥感影像相结合，既可获得高精度的控制点坐标，又能了解更广阔区域的地物属性信息。因此，异构数据采集可谓集中了几何测量与遥感分析的优势，是地理测绘应用向多元化、精细化发展的必由之路。

## 3　多源遥感图像融合方法

### 3.1 全色、多光谱、高光谱图像融合

受限于光学成像机理，遥感图像的空间与光谱分辨率相互制约，单一成像手段无法获取高空间高光谱分辨率的遥感图像。如图4所示，融合两种不同空间、光谱分辨率的图像，是获取高空间高光谱分辨率图像的有效手段（Licciardi等，2012）。通过融合高分辨率的全色图像与多光谱图像，可以将多光谱图像的空间分辨率提升数倍。类似地，融合高分辨率的多光谱图像与低分辨率的高光谱图像，可以极大提升高光谱图像的空间分辨率。这一类图像融合技术又被称作遥感图像空谱融合，由于能够突破成像系统空间与光谱分辨率之间的固有矛盾，空谱融合是遥感图像融合领域的热点问题

现有的空谱融合对象主要是全色图像与多光谱图像、全色图像与高光谱图像、多光谱图像与高光谱图像。从波段数量来说，全色图像与多光谱或高光谱图像的融合属于“一对多”的融合，多光谱图像与高光谱图像的融合属于“多对多”的融合。在图像融合之前，一般都要对图像进行几何校正、正射校正等预处理，再对两幅待融合图像进行配准。

全色图像与多光谱图像融合的研究开始最早，发展时间最长，也被称为全色锐化（Pansharpening），现有方法可分为3类。第1类是空间信息注入法。这类方法通过空间变换、多尺度分析等手段提取高空间分辨率全色图像的空间信息，并将提取出来的空间信息尽可能无损的注入到低空间分辨率的多光谱图像中。代表性方法有Gram-Smidt变换、Brovey算法等（Mura等，2015；Fasbender等，2008）。这类方法的优势是能够较好的保留光谱信息；缺点是由于提取的空间信息仅包含特定谱段范围内的空间结构，与低空间分辨率图像的空间结构并不完全匹配，因此容易产生空间结构失真。第2类是光谱信息注入法。代表性的方法有颜色空间变换法、主成分分析法等（Zhang和Hong，2005；Ghadjati等，2019），这类方法通过线性或者非线性的图像变换将高光谱分辨率的图像变换到新的投影空间，分解为光谱成分和空间成分，并用全色图像去替换其空间成分，再经过逆变换获得融合图像。这类方法能较好的保留空间信息，但光谱信息会产生一定的失真。第3类是空谱采样建模法，其核心思想是将融合问题看作是一个逆向重建问题，通过建立源图像与融合结果之间的关系模型，优化求解得到融合结果。这类方法由于模型的严谨性，相比于前两类方法，能够更好的保持图像的空间与光谱信息。此外，为进一步优化融合效果，在融合过程中可引入概率统计和先验约束，但模型的求解会更加复杂。代表性方法有基于稀疏表示的方法（Li等，2013；Jiang等，2012）、基于深度网络的方法（Scarpa等，2018）等。

全色与高光谱的融合与全色锐化较为相似，但是由于高光谱图像空间分辨率很低，像元之间会存在混淆（Winter和Winter，2002；Hardie等，2004），学者们多采用模型优化求解的方法来解决这类融合问题。多光谱与高光谱的融合相比于全色与多光谱图像融合，更具有挑战性。多光谱与高光谱的融合方法可分为3类，基于全色锐化的方法、基于成像模型的方法和基于深度网络的方法。

基于全色锐化的方法即将多光谱与全色融合的方法扩展应用在多光谱与高光谱图像的融合中。在扩展应用全色锐化融合方法时，波段的对应性是必须要考虑的因素，如Chen等（2014）将高光谱图像的波段分组，通过传统的全色锐化方法对每个波段小组进行融合；Selva等（2015）通过将高光谱波段与多光谱的波段建立分组关系，有效地将一些经典多尺度分析的方法应用于多光谱与高光谱图像的融合。

基于成像模型的方法主要包括基于混合像元分解的方法和基于张量分解的方法 （Li和Yang，2011；Dian等，2019）。基于混合像元分解的方法利用了光谱分解原理，在传感器特性的约束或先验下，分别从高光谱图像和多光谱图像中获取端元信息和高分辨率丰度矩阵，来重建融合后图像，其主要的性能影响因素在于光谱基的维度和矩阵系数的估计。基于张量分解的方法通过将高光谱图像表示成三维张量，利用光谱字典、张量核去逼近高空间和光谱分辨率的融合结果，其主要性能影响因素在于谱字典的构建和张量核的估计。此外，研究人员还提出了基于耦合非负矩阵分解（CNMF）的多光谱、高光谱图像融合技术（Yokoya等，2012）、基于低秩分解（LRF）的图像融合技术（Zhang等，2017）和基于耦合稀疏张量分解（CSTF）的图像融合技术（Li等，2018）等。

基于深度网络的方法将低分辨率图像作为深度网络的输入，通过学习低、高分辨率图像之间端到端的映射，输出高分辨率的图像（Dong等，2016）。由于深度网络自身特点，这类融合方法的性能提升点在于构造更加合理的损失函数、处理图像残差和使用更深层次的框架结构，因此研究的重点也都偏向于这3个方面。如Han等（2018）提出的PDCon-SSF融合框架，通过在多光谱图像与学习到的特征之间添加连接，获得了显著的性能提升；Shi等（2019）提出的色彩引导的深度残差注意力网络融合框架，将注意机制集成到残差网络中，充分利用了光谱和空间维度的相关性，在图像融合过程中很好的保持了图像的空间与光谱信息（Shoeiby等，2019）。

空谱融合的质量主要是体现在融合图像是否存在严重的空间失真和光谱失真。根据是否有标准的高分辨率的参考图像，客观评价指标分为有参考评价指标和无参考评价指标。常用的有参考评价指标有均方根误差（RMSE）、峰值信噪比（PSNR）、结构相似度（SSIM）、光谱角映射（SAM）、相对全局误差（ERGAS）和全局图像质量指标（UIQI）等（Wang和Bovik，2002；Wang等，2004；Wald，1999）；无参考评价指标有QNR参数（Alparone等，2008）、JQM参数（Palubinskas，2014）等。

全色、多光谱与高光谱之间的融合在实际生活中应用中十分广泛，如Tiwari等（2010）将IKONOS卫星的多光谱图像与Hyperion的高光谱图像融合，用以提高道路检测的精度，方法在印度的台拉登城区域获得较好结果；胡博和汪西原（2016）将资源三号的全色与多光谱图像融合，用以提取耕地信息，方法在宁夏平原区域获得了不错的效果。

全色、多光谱和高光谱图像都是光学传感器获取的图像，它们之间的主要区别在于光谱分辨率和空间分辨率的不同，空谱融合的目的是提升图像的光谱和空间分辨率。虽然空谱融合的研究已经发展多年，但仍存在着诸多技术难题亟待解决。

（1）当空谱融合的图像是不同卫星获取的数据时，源图像之间的配准误差会对融合性能产生较大影响，尤其是全色图像与高光谱图像、多光谱图像与高光谱图像的融合，现有成像平台无法同时获取不同分辨率的多光谱与高光谱图像，这类图像的配准难度更大，是空谱融合亟需解决的难题。

（2）不同成像手段光谱响应区间不一致时，图像融合过程中易产生空间和光谱结构失真，尤其是全色图像与高光谱图像的融合，由于全色图像与高光谱图像的光谱响应区间存在很大差异，融合过程中往往难以重构出真实的高分辨率空间信息。

（3）不同成像手段间的空间分辨率和光谱分辨率差异越大，空间与光谱信息的压缩比例就越大。这说明多分辨率图像融合存在性能极限，当图像空间分辨率的比值超出某个范围时，现有方法往往难以重构出高质量的高分辨率高光谱图像。

（4）相比于其他图像融合方法，基于成像模型的图像融合方法在融合过程中能够更好的保持图像的空间与光谱信息，但这类方法通常需要求解复杂的优化问题，计算代价也会更大，如何降低此类算法的计算代价是亟需解决的技术难题。

（5）多光谱与全色图像融合的研究趋于瓶颈，不同融合方法的性能差异在视觉上已经难以区分，而全色与高光谱图像融合、多光谱与高光谱图像融合的研究仍有较大发展空间。尤其是实验中使用的全色与高光谱融合数据、多光谱与高光谱融合数据多是通过对真实高光谱图像进行空间下采样或是光谱下采样的方式生成，采用真实卫星获取的多光谱、高光谱图像进行数据融合的研究工作较少。

（6）全色、多光谱和高光谱图像的融合研究是领域内的热点，但如何将图像融合算法与实际应用问题相结合仍存在诸多问题。从应用的角度改进融合算法的性能和效率，增加融合算法的实用性，是多源遥感图像空谱融合的挑战难题，也是其未来的发展趋势。

### 3.2　全色/多光谱与合成孔径雷达图像融合

### 全色/多光谱与合成孔径雷达图像融合

合成孔径雷达（SAR）是一种主动的微波遥感成像方式，能够全天时全天候工作。SAR图像能够反映地物的介电特性和几何特性，但由于其侧视相干成像方式，图像噪声污染较严重且目视效果不佳（Thompson，2001）。全色图像能够提供地物精细的空间结构信息。多光谱图像光谱信息较丰富，但空间分辨率通常低于全色与SAR图像。因此，SAR图像与全色、多光谱图像的融合，综合利用了光学成像和主动成像的独特优势，能够生成更高质量的融合图像。如图5所示，将全色图像与SAR图像进行融合，融合图像既能够保留全色图像的空间结构信息，又能够保留SAR图像中目标的后向散射信息，能够更好地进行后续的图像分析与解译（Seo和Eo，2020）。此外，将低分辨率多光谱图像与高分辨率SAR图像进行融合可有效提升多光谱图像的空间分辨（Chandrakanth等，2011）。

针对全色、多光谱与SAR图像的融合，国内外学者开展了大量研究。现有全色/多光谱与SAR图像融合方法可分为像素级、特征级和决策级融合3个层次 （Kulkarni和Rege，2020）。在进行融合之前，通常需对SAR图像进行去噪并对两幅源图像进行配准。对于像素级融合，配准的精度直接影响图像融合的性能。而不同去噪方法对细节信息的保留程度不同，适用于不同层次的图像融合。因此，图像融合中SAR图像预处理方法的选择尤为重要（孙越 等，2019）。

像素级图像融合直接对图像中的像素进行融合，结果是一副包含更多场景信息的融合图像。像素级融合的优势是能够尽可能保留全色、多光谱与SAR图像的原始信息。Ghassemian（2016）将像素级融合方法归纳为成分替换法、多分辨率分析法与基于成像模型的方法。成分替换法对低空间分辨率的多光谱图像进行图像变换，将其分解为空间和光谱成分，再用高空间分辨率的SAR图像去替代其空间成分，最后进行逆变换得到融合图像。常用的方法有主成分分析法（PCA）、GS法（Gram-Schmidt）、IHS变换法（Intensity-Hue-Saturation）、Brovey变换法、高通滤波法（HPF）等（Gupta等，2013；Chen等，2010；Feng等，2019）。这类方法原理简单，计算效率高，但容易产生光谱失真。多分辨率分析法通过拉普拉斯金字塔、小波分析等多分辨率分析方法，提取SAR图像或全色图像的空间信息，并通过不同图像多分辨表示系数的加权融合与重建得到融合图像。代表性的方法有基于拉普拉斯金字塔的方法、基于小波变换的方法、基于Shearlet变换的方法、基于Contourlet变换的方法等（邰建豪
 等，2017；易维等，2018）。这类方法计算复杂度更高，在图像存在配准误差效果更佳鲁棒，但易产生空间失真。基于成像模型的方法主要包括基于变分模型和稀疏表示模型的融合方法。稀疏表示模型将图像融合问题视为图像复原问题，能够有效减少融合过程中产生的空间与光谱结构失真，但其字典学习与稀疏编码是两个挑战性的难题，算法的计算复杂度较高（Ghahremani和Ghassemian，2016）。除上述3种方法外，研究人员还提出将前3种方法进行集成，以综合利用不同类型像素级融合方法的优势，减少光谱和空间失真的同时，降低方法的计算复杂度。例如，
 IHS 
图像融合方法对空间细节保留较好，但是会引入光谱失真。多分辨率分析方法能够很好保留图像光谱信息，但易引入光谱失真。因此，研究人员们提出了IHS和多分辨率分析相结合的图像融合方法（Alparone等，2004）；为了降低稀疏表示模型的计算复杂度，也有学者提出结合稀疏表示与IHS变换的图像融合方法（Liu等，2016；Zhang等，2016）。

特征级融合是从SAR与多光谱图像中提取显著特征，如边缘、角点、轮廓、纹理等，并将这些特征进行融合，得到辨识度更高的融合特征。例如，将SAR图像和多光谱图像中的边缘特征进行匹配与融合，可以得到地物更完整、更清晰的边缘特征图（李璟旭，2009）。决策级的融合从某种意义上来说是多源图像深层语义信息的融合，它从预处理后的图像中提取地物要素信息，并对这些信息进行融合生成最终的地物分类结果（Waske等，2007）。特征级和决策级图像融合都不会保留图像的原始像素信息，但在实际遥感应用中，特征级与决策级融合效率更高、融合结果往往能直接服务于具体的应用需求。

SAR图像与全色、多光谱图像融合的性能评估，根据融合的层次不同也会有所差异。像素级融合常用的评价指标包括SAM、ERGAS、RMSE、SSIM等，特征级与决策级的融合则根据融合前后，地物分类、变化检测或目标探测性能的差异来评估融合性能 （Liu等，2015）。

SAR图像与全色、多光谱图像的融合已成功应用于土地覆盖分类和地理环境监测等遥感应用问题（Bilgin等，2015；Gianinetto等，2015）。许璟等（2015）将Radasat卫星获取的SAR图像与Landsat 卫星获取的多光谱图像进行融合，研究结果显示图像融合能够有效提升高原山区地形地势分析的精度。Haldar和Patnaik等（2010）将Radarsat卫星获取的多时相SAR数据与星载多光谱图像进行融合，进行作物的种类识别并估算种植面积。Brunner等（2010）融合了QuickBird和WorldView-1获取的光学图像以及TerraSAR-X和COSMO-SkyMed获取的SAR图像，通过特征级的图像融合与分类，分析了汶川地震中映秀镇的灾后变化，并进行了灾害评估。Yuan等（2020）以北京为案例，融合Sentinel-1卫星获取的SAR图像和Landsat 8获取的多光谱图像，实验证明融合后地物分类精度更高，地物要素信息的提取更加准确。Seo等（2018）使用随机森林方法融合Kompsat-5 SAR图像的地表粗糙度特征与Landsat 8多光谱图像的地物光谱特征，有效提升了地物变化检测的精度。

总体来说，SAR与多光谱、高光谱图像的融合主要存在如下挑战性难题：

（1）由于成像的基本原理不同，相比于全色、多光谱、高光谱图像之间的融合，SAR图像与全色、多光谱图像的结构差异更大，导致像素级融合过程中，易产生严重的空间与光谱失真。

（2）SAR成像本身，不可避免会产生特有的斑点噪声，且SAR与多光谱、高光谱图像之间还存在不可避免的配准误差，这些因素均会对融合性能造成影响。

（3）随着深度学习技术的兴起，近年来SAR与全色、多光谱图像的融合正朝着深层特征表示与语义信息融合的方向发展，探索新的跨模态特征与决策融合方法，是SAR图像与全色、多光谱图像融合的热点问题，具有十分重要的意义（Idol等，2015）。

### 3.3 多光谱/高光谱与激光雷达图像融合

激光雷达图像能够准确描述地物的3维空间结构，但难以获取地物精细的光谱信息。仅使用LiDAR图像这一单一数据源，往往难以实现地物的精确分类和识别。多光谱和高光谱遥感图像具有丰富的光谱信息，与LiDAR图像具有很好的互补性（乔纪纲 等，2011）。因此，综合利用LiDAR图像获取的3维结构信息与多光谱、高光谱图像获取的地物光谱信息，可极大提升遥感图像地物分类的精度和可信度，为地物的精确识别开辟了新途径。如图6所示，结合LiDAR图像的高程信息可以有效去除多光谱图像中的阴影；此外，将LiDAR图像和高光谱图像的分类结果进行融合，能够极大提高地物分类精度 （Berger等，2013；Rasti等，2017）。

由于多光谱、高光谱图像与LiDAR图像属于异质传感器数据的融合，目前的研究多是通过特征级和决策级的方法来进行融合（张良培和沈焕锋，2016），并逐渐形成了“特征提取—特征融合—图像分类—决策融合—分类后处理”的融合流程（曹琼 等，2019）。特征级融合与决策级融合具有各自的优势，特征级融合能针对图像的特点提取特征来进行融合，融合的灵活性更高；决策级融合可以避免不同数据特征的不一致性，融合的鲁棒性更强（童庆禧 等，2006）。也有学者研究如何将特征级和决策级融合的方法相结合，来兼顾两者的优势。曹琼等（2019）提出了多级融合的方法来综合利用高光谱图像与LiDAR图像进行城市地物的精细分类，具体流程是先提取两幅源图像的空间、光谱和高程信息，并对特征进行融合与分类，然后使用LiDAR图像生成的建筑物掩膜，进一步对分类结果进行优化，得到最终的地物分类结果。Zhong等（2017）将高光谱图像与LiDAR图像融合，并通过加权投票的决策融合策略得到分类结果；Chen等（2017）将Landsat 8、环境一号卫星和Terra卫星获取的多光谱、高光谱和激光雷达图像进行融合，结果表明融合多源遥感成像手段获取的光谱、高度、角度等信息，能够获得比单一来源遥感图像更高的分类精度。袁鹏飞等（2018）融合LiDAR图像的三维特征和多光谱图像的强度、密度、平坦度等特征，实现城市复杂环境下道路中心线的精确提取。吴孟凡等（2017）将Worldview-2获取的多光谱图像与机载LiDAR数据融合吗，估算城市不透水层分布情况，实验表明LiDAR图像的引入能够更好的区分植被阴影与不透水层，进而提高不透水层的估算精度。

LiDAR图像与多光谱、高光谱的融合是遥感图像融合领域近年来逐渐兴起的热点问题。总体来说，LiDAR图像与多光谱、高光谱图像融合主要存在如下挑战性难题：

（1）LiDAR图像与多光谱、高光谱图像的融合属于多模态图像融合，两种不同模态图像反映的目标特性存在很大差异，如何实现特性各异的信息的跨模态联合表示与提取是LiDAR与多光谱、高光谱图像融合亟需解决的难题；

（2）LiDAR图像与多光谱、高光谱图像融合多是特征级或决策级的融合。特征提取的方法、分类器的设计在融合过程中发挥了重要作用。因此，设计最优的特征级、决策级或多级图像融合框架，充分发挥不同特征提取与分类方法的优势，是LiDAR图像与多光谱、高光谱图像融合的挑战性难题。

（3）LiDAR图像与多光谱、高光谱图像融合在城市制图、林业调查等领域取得了成功应用。在后续研究中，探索LiDAR图像与多光谱、高光谱图像融合新的应用问题，具有十分重要的意义。

### 3.4　其他类型的多源遥感图像融合

除上述国内外研究人员普遍关注的遥感图像融合问题外，近年来，热红外遥感图像、夜光遥感图像、视频遥感数据和立体遥感图像的融合逐渐兴起。其融合的目的同样是通过综合利用不同来源遥感图像的特点和优势，获得更高质量的融合图像，或是进一步提升后续目标探测与地物分类的精度（Zhan等，2011；Huang和Song，2012）。

如图7所示，热红外图像主要反映了地面的温度分布信息，但空间分辨率低；相比于热红外图像，全色与多光谱图像的空间分辨率更高，将热红外图像与全色图像或多光谱图像融合能够得到更高空间分辨率的地表温度数据。例如，姚为和韩敏（2010）通过神经网络方法将ETM+ 数据集中的多光谱图像与热红外图像融合，获得了扎龙湿地高空间分辨率的地表温度分布图像；Jin和Han（2017） 提出基于稀疏表示的图像融合方法，将Landsat 7的热红外图像和全色图像进行融合，显著提升了地表温度分布图的空间分辨率。

除空间和光谱分辨率外，卫星的重访频率也是遥感图像的一个重要属性。一方面，卫星传感器在图像分辨率和重访频率之间必有折中，但作为研究地表特征时空特性的关键，遥感图像的时间和空间分辨率都至关重要；另一方面，多时相遥感影像中包含海量的时空信息，对数据中时空信息的挖掘，可极大地提高遥感数据的利用率（黄波和赵涌泉，2017；Zhu等，2016）。因而，不同时间与空间分辨率的遥感图像融合（时空融合）也是一种不可或缺的技术手段。近年来，多时间分辨率遥感图像融合已被成功应用于作物生长评估、城市变化监测等领域。例如，Gao等（2015）将时间分辨率更高的MODIS多光谱图像和空间分辨率更高的Landsat多光谱图像融合，融合结果继承了Landsat的空间分辨率（30 m）和MODIS的重访频率（每天），被成功应用于农作物的长势分析和监测；张猛和曾永年（2018）以长株潭城市群核心区为例，将MODIS与Landsat融合后的高时空分辨率数据用于估算植被净生产力，结果与实测值保持了较好的一致性。

其他类型的多源遥感图像融合还包括夜间灯光数据、立体图像、视频数据的融合。例如，吴小语和张鹏林等（2015）以武汉市为研究对象，合DMSP夜间遥感数据和Landsat 7获取的多光谱图像来提升城市边界提取精度。张靖宇等（2015）以西沙群岛北岛为研究对象，采用WorldView-2 4波段立体图像数据和非遥感数据（水深点和潮汐表）进行决策级融合，实现了岛屿周边水深的精确反演。

为了鼓励和推动多源遥感数据融合的研究，IEEE地球科学与遥感学会IEEE
 GRSS（IEEE Geoscience and Remote Sensing 
Society）自2006年以来，每年都会举办多源遥感数据融合竞赛，近十年来，比赛主题不仅涉及空谱融合、时空融合、高光谱与LiDAR融合等领域，还包括多角度光学图像、视频数据、地图矢量数据等。近十年来，IEEE
 GRSS数据融合大赛的主题和数据信息如表2所示。从表中可以得出以下结论。

（1）视频、立体等新型遥感数据已出现在2011年、2016年的数据融合竞赛中，随着这类搭载新型传感器的卫星和机载平台的发展，探索针对夜光、视频与立体图像的融合技术是未来的发展方向之一。

（2）现有图像融合方法的输入大多是两种不同不同来源的图像，两种以上不同来源图像如何高效融合仍是多源图像融合亟需解决的技术难题。

（3）除遥感图像数据外，如何融合不同来源的地理信息数据、地面站点数据、不同来源的遥感图像数据是多源遥感图像融合技术进一步发展必须要考虑的问题。

（4）近年来，图像融合正在从像素级的融合往更深层次的特征级与决策级融合的方向发展，地物分类精度等指标在图像融合性能评估中发挥越来越重要的作用。例如2013年—2020年的数据融合竞赛中，均采用地物解译或者分类的精度来评价融合性能。换言之，研究人员逐渐认识到遥感图像融合的最终目的是提高应用场景下地物的解译和识别能力。

### 3.4 GIS 在地理测绘成果表达中的效果

传统地理测绘成果以平面图件为主，如线路图、分区图、地形图等，表达形式单一。随着GIS 技术的发展，地理测绘成果表达形式日益丰富多样。除了平面矢量数据和栅格影像，GIS 还支持三维景观模型、虚拟仿真动画、网络在线服务等多种表现手段，使成果表达不再局限于静态图件。基于三维可视化技术，GIS 能够对复杂多变的地理场景进行逼真的三维重建，突破了传统二维平面的限制，为用户提供身临其境的真实体验。如针对某区域的地形地貌，通过构建三维数字高程模型，不仅能全景展示地物形态，还可模拟飞行、漫游等视角，让人们近距离领略地表起伏的细微变化。此外，三维 GIS 技术还可用于专题领域的成果表达，比如展现三维管线走向、重现古建筑真容、再现历史事件场景等。除了静态的三维场景，GIS 还能生成多种动态动画类成果。基于时空数据和模型，GIS 可模拟自然现象的动态演变过程，如洪水淹没、流域污染扩散、气象系统变化等，为评估灾情提供科学依据。此外，4D 时空模拟更是 GIS 的一大特色，如仿真城市扩展历程、模拟交通流量变化、重现历史事件等，都可以通过动画形象再现。动态表达无疑比静态更具观赏性和直观性，符合 GIS" 可视化 " 的设计理念。

过去的地理图件常常固定在单一尺度，难以满足不同用途的需求。而 GIS 则可实现多尺度无缝切换，为用户提供更灵活、个性化的展示体验。以某测绘区域为例，用户可以根据需要对全局进行多级放大或缩小浏览，从宏观把握整体轮廓，到微观关注细节部位。多尺度展示有利于对复杂地理现象进行全面深入的认知，避免了单一尺度带来的视野狭隘。除了尺度切换，GIS 还支持多视角展现同一地理场景。用户可以通过旋转、平移、倾斜等操作自由调整视角，去除传统的“鸟瞰视角”的限制。比如在城市规划中，不同视角的三维模型能帮助决策者了解建筑群的整体布局，以及对周边环境的影响。而在野外测绘中，不同视角也能最大限度展现复杂地形的细节特征，为勘探工作提供帮助。可见，多视角展示可谓满足了不同应用场景下的个性化需求。正是得益于 GIS 灵活的尺度和视角控制，从而实现了地理空间认知的多元化。即使是同一张图件，用户也可根据自己的期望对其进行自定义显示，更加贴近实际应用需求。这无疑极大提升了地理测绘成果的实用价值。

传统模式下，测绘成果主要以纸质图件或数字文件的形式存在，难以实现广泛传播。而 Web 技术的兴起促进了地理信息的在线发布和共享，从而推动地理测绘成果走出“数据孤岛”。利用 GIS 的 WebGIS 和 WebService 等技术，任何测绘成果均可通过互联网向所有用户开放，享受高效、便捷的在线服务。WebGIS 是 GIS 在互联网上的体现，它通过 Web 浏览器对地理数据进行实时浏览、查询和发布。只需简单登录即可享受各类空间数据服务，如导航寻路、影像地图浏览、三维场景漫游等，非常适合基于网络的各类地理信息应用场景。同时，WebGIS 还支持分布式管理和云存储，有利于地理数据资源的集中式维护和共享利用，克服了单机环境下的局限性。除了 WebGIS，地理信息开放服务也体现在各类 WebService 中。OGC 标准化了诸如 WMS、WFS、WCS 等众多地理信息服务，为跨平台、跨系统的地理数据交换奠定了基础。用户可通过服务接口方便调用发布于网络上的地理数据资源，进而建立各类基于位置的综合应用。比如政府机构基于 WMS 影像服务搭建决策平台，或通过WFS 接三维地形等专题数据，共享和整合地理信息资源，从而提高行政管理和公共服务的水平。

## 4 基于cesium的多源数据融合实现

#### **4.1 系统架构设计**

系统基于 **Cesium** 搭建，分为以下核心模块：

- **数据预处理模块**：实现多源数据的格式转换、投影统一和几何校正。
- **数据管理模块**：采用 **PostGIS** 或 **SQLite** 实现空间数据的高效存储与检索。
- **分析模块**：提供通视分析、遮蔽分析、隧道挖掘计算等核心功能。
- **可视化模块**：支持三维地形、建筑模型和高光谱图层的实时渲染。
- **脚本扩展模块**：允许用户通过简单代码扩展分析与展示功能。

系统架构示意图如下：

```lua
|--- 数据预处理模块 ---|      |--- 数据管理模块 ---|    
|--- 分析模块 --------| <=>  |--- 可视化模块 -----|    
|--- 用户脚本扩展模块 |      |--- API 接口 -------|    

```

#### **4.2 数据融合流程**

##### **4.2.1 数据加载与预处理**

- 使用 **GDAL** 工具处理 **TIFF**、**DEM**、**卫图** 等空间数据。
- 统一数据坐标系至 **WGS84**，分辨率进行多层次匹配。
- 将高光谱数据标准化，提取电磁特征进行波段加权融合。

##### **4.2.2 数据集成与融合**

- **高光谱图层融合**：采用主成分分析（PCA）或深度学习方法，融合多波段信息。
- **地形与模型融合**：将三维倾斜摄影与 DEM 数据结合生成纹理化地形；将 BIM 数据添加底质和电磁特性。
- **多源数据联动**：实现点、线、面与体之间的互操作，满足复杂场景的展示需求。

##### **4.2.3 数据渲染**

- 基于 Cesium 实现融合数据的高效加载与展示。
- 使用 WebGL 技术支持实时渲染，实现流畅的用户交互。

---

#### **4.3 核心功能实现**

##### **4.3.1 通视与遮蔽分析**

- **通视分析**：根据 DEM 和视点位置，计算目标区域的可视性。
- **遮蔽分析**：结合三维模型，评估信号传播的遮挡区域，并生成遮蔽图。

##### **4.3.2 隧道挖掘与分析**

- 提供用户绘制地面路径的功能。
- 根据 DEM 计算路径上距地表最近点和最远点距离。
- 输出隧道路径的三维剖面图，直观展示隧道深度与地形关系。

##### **4.3.3 高光谱自由组合与配置**

- 提供波段选择与权重调整界面，允许用户动态调整融合算法。
- 实现高光谱图层的叠加与对比，为目标识别提供支持。



## 总结与展望
